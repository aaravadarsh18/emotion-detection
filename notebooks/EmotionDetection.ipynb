{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc54ccb",
   "metadata": {},
   "source": [
    "# Emotion Detection — Full Project\n",
    "\n",
    "**Notebook:** reproducible end-to-end workflow for preprocessing, baseline training, transformer fine-tuning, evaluation, analysis, and demo.\n",
    "\n",
    "_Run cells sequentially. Use `python3` kernel._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2451c",
   "metadata": {},
   "source": [
    "## 0 — Setup\n",
    "\n",
    "Install required packages (run once). If you use a virtualenv, activate it first. These versions are suggested for reproducibility; adjust if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2093c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install common dependencies (uncomment if running in a fresh environment)\n",
    "# !python3 -m pip install -U pip\n",
    "# !python3 -m pip install -r requirements.txt\n",
    "\n",
    "# Minimal install commands you can uncomment if needed:\n",
    "# !python3 -m pip install datasets transformers evaluate torch scikit-learn pandas joblib matplotlib seaborn streamlit emoji nbformat\n",
    "print(\"Ready. If packages are missing, install them using pip as commented above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb91b1",
   "metadata": {},
   "source": [
    "## 1 — Dataset overview\n",
    "\n",
    "We use the TweetEval `emotion` dataset from CardiffNLP (via Hugging Face datasets). This cell loads dataset metadata and shows class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"cardiffnlp/tweet_eval\", \"emotion\")\n",
    "for split in ds:\n",
    "    print(split, len(ds[split]))\n",
    "print(\"Labels:\", ds[\"train\"].features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d6beca",
   "metadata": {},
   "source": [
    "## 2 — Preprocessing\n",
    "\n",
    "Apply the project's `preprocess_tweet` function (from `src.preprocessing`). If you modified it during Week 1, this will import and apply it. Otherwise use a simple placeholder cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project's preprocessing pipeline\n",
    "import sys, os\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd()))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "try:\n",
    "    from src.preprocessing import preprocess_tweet\n",
    "except Exception as e:\n",
    "    print(\"Could not import src.preprocessing.preprocess_tweet:\", e)\n",
    "    # Fallback simple preprocessor\n",
    "    import re\n",
    "    def preprocess_tweet(x):\n",
    "        x = str(x).lower()\n",
    "        x = re.sub(r'http\\S+', '', x)\n",
    "        x = re.sub(r'[^\\w\\s#@]', '', x)\n",
    "        x = re.sub(r'\\s+', ' ', x).strip()\n",
    "        return x\n",
    "\n",
    "# Quick sample\n",
    "sample = ds['train']['text'][:5]\n",
    "print([preprocess_tweet(t) for t in sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278eb54b",
   "metadata": {},
   "source": [
    "## 3 — Baseline: TF-IDF + Logistic Regression\n",
    "\n",
    "Train a baseline model (fast). The training script `src/train_baseline.py` does this; below is an inline minimal run example to train on the training split (smaller for notebook demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick baseline training (small subset to keep runtime reasonable in notebook)\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump\n",
    "\n",
    "# prepare small sample\n",
    "train_df = pd.DataFrame(ds['train'])\n",
    "train_df['text_clean'] = train_df['text'].apply(preprocess_tweet)\n",
    "# take a sample for quick demo (comment out to use full data)\n",
    "sample_df = train_df.sample(n=2000, random_state=42) if len(train_df)>2000 else train_df\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), max_features=10000, min_df=2)\n",
    "X = vec.fit_transform(sample_df['text_clean'])\n",
    "y = sample_df['label'].values\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=1000, class_weight='balanced', n_jobs=-1)\n",
    "clf.fit(X_tr, y_tr)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred, target_names=ds['train'].features['label'].names))\n",
    "\n",
    "# save small demo model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "dump(clf, 'models/demo_logreg.joblib')\n",
    "dump(vec, 'models/demo_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9cb1c",
   "metadata": {},
   "source": [
    "## 4 — Evaluation & Visuals\n",
    "\n",
    "Plot confusion matrix and per-class F1. For the notebook demo we show evaluation on the small validation set produced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837fad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ds['train'].features['label'].names\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (demo)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35413dfb",
   "metadata": {},
   "source": [
    "## 5 — Feature importance (TF-IDF + LR)\n",
    "\n",
    "List top tokens per class using the trained Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4322d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "feature_names = np.array(vec.get_feature_names_out())\n",
    "coefs = clf.coef_\n",
    "topk = 15\n",
    "for i, label in enumerate(labels):\n",
    "    top_idx = np.argsort(coefs[i])[-topk:][::-1]\n",
    "    top_feats = feature_names[top_idx]\n",
    "    print(f\"Top features for {label}:\", ', '.join(top_feats[:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe557a3",
   "metadata": {},
   "source": [
    "## 6 — Linguistic analysis\n",
    "\n",
    "Compute tweet lengths and emoji counts per class (train split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6547d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "df_train = pd.DataFrame(ds['train'])\n",
    "df_train['text_clean'] = df_train['text'].apply(preprocess_tweet)\n",
    "df_train['char_len'] = df_train['text'].astype(str).apply(len)\n",
    "df_train['emoji_count'] = df_train['text'].apply(lambda t: sum(1 for ch in str(t) if ch in emoji.EMOJI_DATA))\n",
    "grouped = df_train.groupby('label')[['char_len','emoji_count']].mean().rename(columns={'char_len':'avg_len','emoji_count':'avg_emoji'})\n",
    "print(grouped)\n",
    "# plot avg length\n",
    "grouped['avg_len'].plot.bar(title='Average tweet length by label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22498b00",
   "metadata": {},
   "source": [
    "## 7 — Transformer fine-tuning (RoBERTa)\n",
    "\n",
    "Fine-tuning a transformer is computationally expensive. Use `src/train_transformer.py` for full runs. Below is a short demonstration of how to load a pretrained TweetEval RoBERTa model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "model_name = 'cardiffnlp/twitter-roberta-base-emotion'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "classifier = pipeline('text-classification', model=model, tokenizer=tokenizer, top_k=None)\n",
    "print(classifier('I am extremely happy and excited today!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077d349",
   "metadata": {},
   "source": [
    "## 8 — Streamlit Demo\n",
    "\n",
    "To run the Streamlit app locally (after training and saving models to `models/`):\n",
    "\n",
    "```bash\n",
    "# from project root\n",
    "export STREAMLIT_SERVER_HEADLESS=true\n",
    "streamlit run src/streamlit_app.py\n",
    "```\n",
    "\n",
    "The Model Insights tab reads files from `outputs/` (run `src/feature_analysis.py`, `src/evaluate_model.py` to generate them)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdfddb8",
   "metadata": {},
   "source": [
    "## 9 — Reproducibility & next steps\n",
    "\n",
    "- Freeze dependencies: `python3 -m pip freeze > requirements.txt` and prune non-essential packages.\n",
    "- For final submission, include `models/` small demo files and `outputs/` visuals.\n",
    "\n",
    "---\n",
    "\n",
    "Good luck — run cells progressively and use the existing `src/*.py` scripts for heavy jobs."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
